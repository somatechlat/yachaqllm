# Base training configuration for QLoRA fine-tuning on Qwen2.5-7B-Instruct
model_name: "Qwen/Qwen2.5-7B-Instruct"
output_dir: "outputs/qwen2.5-qlora"
train_path: "data/processed/train.jsonl"
eval_path: "data/processed/validation.jsonl"
max_steps: 1000
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
gradient_accumulation_steps: 8
learning_rate: 0.0002
warmup_steps: 50
logging_steps: 10
save_steps: 100
eval_steps: 100
lora_r: 16
lora_alpha: 32
lora_dropout: 0.05
max_seq_length: 2048
# Uncomment to override target modules for LoRA injection (default covers QKV, MLP projections)
# target_modules:
#   - "q_proj"
#   - "k_proj"
#   - "v_proj"
#   - "o_proj"
#   - "gate_proj"
#   - "up_proj"
#   - "down_proj"
