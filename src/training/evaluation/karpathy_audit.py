#!/usr/bin/env python3
"""
üî¨ KARPATHY TRAINING DATA ALIGNMENT AUDIT
=========================================
Verifies our data matches SOTA fine-tuning best practices:
1. Alpaca format compliance
2. Instruction diversity (no repetition)
3. Output quality (reasoning, length)
4. Token distribution analysis
5. Domain balance
"""

import json
import random
from collections import Counter

INPUT = "data/instruction_dataset/train.jsonl"

def audit():
    print("=" * 70)
    print("  üî¨ KARPATHY TRAINING DATA ALIGNMENT AUDIT")
    print("=" * 70)
    
    # Load data
    data = []
    with open(INPUT, "r", encoding="utf-8") as f:
        for line in f:
            data.append(json.loads(line))
    
    print(f"\nüìä Dataset size: {len(data):,} examples")
    
    # =========================================================================
    # CHECK 1: Alpaca Format Compliance
    # =========================================================================
    print("\n" + "=" * 50)
    print("CHECK 1: Alpaca/Stanford Format Compliance")
    print("=" * 50)
    
    required_keys = ["instruction", "input", "output"]
    format_errors = 0
    
    for i, item in enumerate(data[:1000]):  # Sample first 1000
        for key in required_keys:
            if key not in item:
                format_errors += 1
                print(f"  ‚ùå Missing '{key}' at index {i}")
    
    if format_errors == 0:
        print("  ‚úÖ PASS: All examples have instruction/input/output keys")
    else:
        print(f"  ‚ùå FAIL: {format_errors} format errors found")
    
    # =========================================================================
    # CHECK 2: Instruction Diversity (Karpathy: High Entropy)
    # =========================================================================
    print("\n" + "=" * 50)
    print("CHECK 2: Instruction Diversity (Karpathy: High Entropy)")
    print("=" * 50)
    
    instructions = [d["instruction"] for d in data]
    unique_instructions = set(instructions)
    duplicates = len(instructions) - len(unique_instructions)
    uniqueness = len(unique_instructions) / len(instructions) * 100
    
    print(f"  Total instructions: {len(instructions):,}")
    print(f"  Unique instructions: {len(unique_instructions):,}")
    print(f"  Duplicates: {duplicates}")
    print(f"  Uniqueness: {uniqueness:.1f}%")
    
    if uniqueness >= 99:
        print("  ‚úÖ PASS: High diversity (>99% unique)")
    elif uniqueness >= 95:
        print("  ‚ö†Ô∏è WARNING: Some duplication (95-99% unique)")
    else:
        print("  ‚ùå FAIL: Too many duplicates (<95% unique)")
    
    # =========================================================================
    # CHECK 3: Output Quality (Reasoning Length)
    # =========================================================================
    print("\n" + "=" * 50)
    print("CHECK 3: Output Quality (Length & Reasoning)")
    print("=" * 50)
    
    output_lengths = [len(d["output"]) for d in data]
    avg_length = sum(output_lengths) / len(output_lengths)
    min_length = min(output_lengths)
    max_length = max(output_lengths)
    
    # Check for reasoning indicators
    reasoning_indicators = ["porque", "por lo tanto", "c√°lculo", "resultado", "base legal", 
                            "seg√∫n", "art√≠culo", "art.", "f√≥rmula", "paso", "**"]
    has_reasoning = sum(1 for d in data if any(ind in d["output"].lower() for ind in reasoning_indicators))
    
    print(f"  Avg output length: {avg_length:.0f} chars")
    print(f"  Min/Max: {min_length}/{max_length} chars")
    print(f"  With reasoning indicators: {has_reasoning:,}/{len(data):,} ({has_reasoning/len(data)*100:.1f}%)")
    
    if avg_length >= 300 and has_reasoning/len(data) >= 0.8:
        print("  ‚úÖ PASS: Good output quality with reasoning")
    elif avg_length >= 200:
        print("  ‚ö†Ô∏è WARNING: Outputs could be longer")
    else:
        print("  ‚ùå FAIL: Outputs too short for quality training")
    
    # =========================================================================
    # CHECK 4: Token Estimation (for training cost)
    # =========================================================================
    print("\n" + "=" * 50)
    print("CHECK 4: Token Estimation")
    print("=" * 50)
    
    total_chars = sum(len(d["instruction"]) + len(d["output"]) for d in data)
    estimated_tokens = total_chars / 4  # ~4 chars per token
    
    print(f"  Total characters: {total_chars:,}")
    print(f"  Estimated tokens: {estimated_tokens:,.0f}")
    print(f"  Tokens per example: {estimated_tokens/len(data):.0f}")
    
    if 10_000_000 <= estimated_tokens <= 100_000_000:
        print("  ‚úÖ PASS: Token count in optimal range for fine-tuning")
    elif estimated_tokens < 10_000_000:
        print("  ‚ö†Ô∏è WARNING: Could use more data (< 10M tokens)")
    else:
        print("  ‚ö†Ô∏è WARNING: Large dataset, will take longer to train")
    
    # =========================================================================
    # CHECK 5: Domain Distribution
    # =========================================================================
    print("\n" + "=" * 50)
    print("CHECK 5: Domain Distribution")
    print("=" * 50)
    
    domain_keywords = {
        "TRIBUTARIO": ["iva", "impuesto", "retenci√≥n", "rimpe", "sri", "tributar"],
        "LABORAL": ["despido", "sueldo", "iess", "trabajo", "laboral", "horas extra"],
        "SERCOP": ["sercop", "licitaci√≥n", "contrataci√≥n", "compras p√∫blicas"],
        "LEGAL": ["legal", "penal", "civil", "constituci√≥n", "codigo", "art√≠culo"],
        "ADUANAS": ["aduana", "importa", "exporta", "senae", "arancel"],
        "LOPDP": ["datos personales", "lopdp", "protecci√≥n de datos"],
        "AMBIENTE": ["ambient", "licencia ambiental", "mae"],
        "MUNICIPAL": ["municipal", "patente", "cootad", "gad"],
    }
    
    domain_counts = Counter()
    for d in data:
        text = (d["instruction"] + " " + d["output"]).lower()
        for domain, keywords in domain_keywords.items():
            if any(kw in text for kw in keywords):
                domain_counts[domain] += 1
                break
        else:
            domain_counts["OTROS"] += 1
    
    print("  Distribution:")
    for domain, count in domain_counts.most_common():
        pct = count / len(data) * 100
        print(f"    {domain}: {count:,} ({pct:.1f}%)")
    
    # =========================================================================
    # CHECK 6: Sample Quality Review
    # =========================================================================
    print("\n" + "=" * 50)
    print("CHECK 6: Random Sample Quality Review")
    print("=" * 50)
    
    samples = random.sample(data, 3)
    for i, s in enumerate(samples, 1):
        print(f"\n  --- Sample {i} ---")
        print(f"  Q: {s['instruction'][:80]}...")
        print(f"  A: {s['output'][:150]}...")
        
        # Quality indicators
        has_structure = "**" in s["output"] or "|" in s["output"]
        has_legal = "art" in s["output"].lower() or "ley" in s["output"].lower()
        has_numbers = "$" in s["output"] or "%" in s["output"]
        
        print(f"  [Structure: {'‚úÖ' if has_structure else '‚ùå'}] [Legal Ref: {'‚úÖ' if has_legal else '‚ùå'}] [Numbers: {'‚úÖ' if has_numbers else '‚ùå'}]")
    
    # =========================================================================
    # FINAL SCORE
    # =========================================================================
    print("\n" + "=" * 70)
    print("  üìä FINAL KARPATHY ALIGNMENT SCORE")
    print("=" * 70)
    
    score = 0
    max_score = 6
    
    if format_errors == 0: score += 1
    if uniqueness >= 99: score += 1
    if avg_length >= 300: score += 1
    if has_reasoning/len(data) >= 0.8: score += 1
    if 10_000_000 <= estimated_tokens <= 100_000_000: score += 1
    if len(domain_counts) >= 4: score += 1
    
    print(f"\n  Score: {score}/{max_score}")
    
    if score >= 5:
        print("  üèÜ EXCELLENT: Data is well-aligned with Karpathy/SOTA methodology")
        print("  ‚úÖ READY FOR TRAINING")
    elif score >= 4:
        print("  ‚úÖ GOOD: Minor improvements possible but acceptable")
        print("  ‚úÖ CAN PROCEED WITH TRAINING")
    elif score >= 3:
        print("  ‚ö†Ô∏è FAIR: Some issues should be addressed")
    else:
        print("  ‚ùå POOR: Major issues need fixing before training")
    
    print("\n" + "=" * 70)

if __name__ == "__main__":
    audit()
